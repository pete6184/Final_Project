{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into a pandas DataFrame, drop id column\n",
    "df = pd.read_csv(\"Resources/Data/ThoracicSurgery.csv\")\n",
    "df = df.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data for classifier \n",
    "target = df[\"Risk1Yr\"]\n",
    "target_names = [\"T\", \"F\"]\n",
    "data = df.drop(\"Risk1Yr\", axis=1)\n",
    "data = pd.get_dummies(data)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8617021276595744"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and score random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.18112493347465042, 'PRE5'),\n",
       " (0.17134144561789622, 'PRE4'),\n",
       " (0.159356351562549, 'AGE'),\n",
       " (0.03002138278667311, 'DGN_DGN5'),\n",
       " (0.027762292765678532, 'PRE14_OC11'),\n",
       " (0.0267437945513764, 'DGN_DGN3'),\n",
       " (0.025202968373976894, 'PRE14_OC12'),\n",
       " (0.023257866712346614, 'PRE14_OC14'),\n",
       " (0.02244120352880268, 'DGN_DGN2'),\n",
       " (0.02137556421800881, 'PRE11_F'),\n",
       " (0.02055635109184197, 'PRE11_T'),\n",
       " (0.02047555773552332, 'PRE6_PRZ1'),\n",
       " (0.019714743869018902, 'PRE8_T'),\n",
       " (0.01939140105620525, 'PRE17_T'),\n",
       " (0.019262892924332534, 'PRE8_F'),\n",
       " (0.01775123542926093, 'PRE14_OC13'),\n",
       " (0.016005591991755153, 'PRE17_F'),\n",
       " (0.01587028845481526, 'PRE10_F'),\n",
       " (0.015693540981493087, 'PRE7_T'),\n",
       " (0.01523623043631555, 'PRE9_T'),\n",
       " (0.015185140501332177, 'PRE10_T'),\n",
       " (0.015088366391897005, 'PRE6_PRZ0'),\n",
       " (0.013996162206847072, 'PRE7_F'),\n",
       " (0.013863661637729941, 'PRE30_F'),\n",
       " (0.013675864997954838, 'PRE30_T'),\n",
       " (0.013226252982040509, 'PRE9_F'),\n",
       " (0.013160973805714652, 'DGN_DGN4'),\n",
       " (0.010295785950856968, 'DGN_DGN8'),\n",
       " (0.009734544491668303, 'PRE6_PRZ2'),\n",
       " (0.007025810452780239, 'PRE25_T'),\n",
       " (0.004979847123793602, 'PRE25_F'),\n",
       " (0.0003241907606091642, 'PRE19_F'),\n",
       " (0.00028853637429157656, 'DGN_DGN6'),\n",
       " (0.00023537179867021393, 'PRE19_T'),\n",
       " (0.00016172485059850987, 'PRE32_F'),\n",
       " (0.00011798637402334713, 'PRE32_T'),\n",
       " (5.414173667131391e-05, 'DGN_DGN1')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the features by their importance\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish X and y\n",
    "X = data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d9cf842e2447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# convert encoded labels to one-hot-encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0my_train_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0my_test_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# label-encode target data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=37))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit (train) the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  make predictions\n",
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the SVC Model\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # fit the model using the grid search estimator \n",
    "GridSearchCV(estimator=SVC(kernel='linear'),\n",
    "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
    "             verbose=2)\n",
    " # list the best parameters, score for this dataset\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with hypertuned model\n",
    "predictions = grid.predict(X_test_scaled)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the best score\n",
    "print('Test Acc: %.3f' % grid.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "metrics.f1_score(y_test, predictions, average='weighted', labels=np.unique(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate classification report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"T\", \"F\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['DGN', 'PRE4', 'PRE5', 'PRE6', 'PRE7', 'PRE8', 'PRE9', 'PRE10', 'PRE11', 'PRE14', 'PRE17', 'PRE19', 'PRE25', 'PRE30', 'PRE32', 'AGE', 'Risk1Yr']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "           \"DGN\",\n",
    "           \"PRE4\",\n",
    "           \"PRE5\",\n",
    "           \"PRE6\",\n",
    "           \"PRE7\",\n",
    "           \"PRE8\",\n",
    "           \"PRE9\",\n",
    "           \"PRE10\",\n",
    "           \"PRE11\",\n",
    "           \"PRE14\",\n",
    "           \"PRE17\",\n",
    "           \"PRE19\",\n",
    "           \"PRE25\",\n",
    "           \"PRE30\",\n",
    "           \"PRE32\",\n",
    "           \"AGE\",\n",
    "           \"Risk1Yr\",\n",
    "]\n",
    "\n",
    "lived_df = new_df.loc[new_df[\"Risk1Yr\"] == \"F\", columns ]\n",
    "lived_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts\n",
    "pre7_df = lived_df[\"PRE7\"].value_counts()\n",
    "pre8_df = lived_df[\"PRE8\"].value_counts()\n",
    "pre9_df = lived_df[\"PRE9\"].value_counts()\n",
    "pre10_df = lived_df[\"PRE10\"].value_counts()\n",
    "pre11_df = lived_df[\"PRE11\"].value_counts()\n",
    "pre14_df = lived_df[\"PRE14\"].value_counts()\n",
    "pre17_df = lived_df[\"PRE17\"].value_counts()\n",
    "pre19_df = lived_df[\"PRE19\"].value_counts()\n",
    "pre25_df = lived_df[\"PRE25\"].value_counts()\n",
    "pre30_df = lived_df[\"PRE30\"].value_counts()\n",
    "pre32_df = lived_df[\"PRE32\"].value_counts()\n",
    "\n",
    "print(pre7_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre8_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre9_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre10_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre11_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre14_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre17_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre19_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre25_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre30_df)\n",
    "print(f\"-------------------------\")\n",
    "print(pre32_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DGN_df = lived_df[\"DGN\"].value_counts()\n",
    "DGN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataframe - adjusting string values into numeric processible values\n",
    "new_df['DGN'] = np.where(new_df['DGN'] == 'DGN1', '1', new_df['DGN'] )\n",
    "new_df['DGN'] = np.where(new_df['DGN'] == 'DGN2', '2', new_df['DGN'] )\n",
    "new_df['DGN'] = np.where(new_df['DGN'] == 'DGN3', '3', new_df['DGN'] )\n",
    "new_df['DGN'] = np.where(new_df['DGN'] == 'DGN4', '4', new_df['DGN'] )\n",
    "new_df['DGN'] = np.where(new_df['DGN'] == 'DGN5', '5', new_df['DGN'] )\n",
    "new_df['DGN'] = np.where(new_df['DGN'] == 'DGN6', '6', new_df['DGN'] )\n",
    "new_df['DGN'] = np.where(new_df['DGN'] == 'DGN8', '8', new_df['DGN'] )\n",
    "new_df['PRE6'] = np.where(new_df['PRE6'] == 'PRZ2', '2', new_df['PRE6'] )\n",
    "new_df['PRE6'] = np.where(new_df['PRE6'] == 'PRZ1', '1', new_df['PRE6'] )\n",
    "new_df['PRE6'] = np.where(new_df['PRE6'] == 'PRZ0', '0', new_df['PRE6'] )\n",
    "new_df['PRE14'] = np.where(new_df['PRE14'] == 'OC11', '11', new_df['PRE14'] )\n",
    "new_df['PRE14'] = np.where(new_df['PRE14'] == 'OC12', '12', new_df['PRE14'] )\n",
    "new_df['PRE14'] = np.where(new_df['PRE14'] == 'OC13', '13', new_df['PRE14'] )\n",
    "new_df['PRE14'] = np.where(new_df['PRE14'] == 'OC14', '14', new_df['PRE14'] )\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning - copying dataframe to allow other adjustments for later\n",
    "cleaned_df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['PRE7'] = np.where(cleaned_df['PRE7'] == 'T', '0', cleaned_df['PRE7'] )\n",
    "cleaned_df['PRE7'] = np.where(cleaned_df['PRE7'] == 'F', '1', cleaned_df['PRE7'] )\n",
    "cleaned_df['PRE8'] = np.where(cleaned_df['PRE8'] == 'T', '0', cleaned_df['PRE8'] )\n",
    "cleaned_df['PRE8'] = np.where(cleaned_df['PRE8'] == 'F', '1', cleaned_df['PRE8'] )\n",
    "cleaned_df['PRE9'] = np.where(cleaned_df['PRE9'] == 'T', '0', cleaned_df['PRE9'] )\n",
    "cleaned_df['PRE9'] = np.where(cleaned_df['PRE9'] == 'F', '1', cleaned_df['PRE9'] )\n",
    "cleaned_df['PRE10'] = np.where(cleaned_df['PRE10'] == 'T', '0', cleaned_df['PRE10'] )\n",
    "cleaned_df['PRE10'] = np.where(cleaned_df['PRE10'] == 'F', '1', cleaned_df['PRE10'] )\n",
    "cleaned_df['PRE11'] = np.where(cleaned_df['PRE11'] == 'T', '0', cleaned_df['PRE11'] )\n",
    "cleaned_df['PRE11'] = np.where(cleaned_df['PRE11'] == 'F', '1', cleaned_df['PRE11'] )\n",
    "cleaned_df['PRE17'] = np.where(cleaned_df['PRE17'] == 'T', '0', cleaned_df['PRE17'] )\n",
    "cleaned_df['PRE17'] = np.where(cleaned_df['PRE17'] == 'F', '1', cleaned_df['PRE17'] )\n",
    "cleaned_df['PRE19'] = np.where(cleaned_df['PRE19'] == 'T', '0', cleaned_df['PRE19'] )\n",
    "cleaned_df['PRE19'] = np.where(cleaned_df['PRE19'] == 'F', '1', cleaned_df['PRE19'] )\n",
    "cleaned_df['PRE25'] = np.where(cleaned_df['PRE25'] == 'T', '0', cleaned_df['PRE25'] )\n",
    "cleaned_df['PRE25'] = np.where(cleaned_df['PRE25'] == 'F', '1', cleaned_df['PRE25'] )\n",
    "cleaned_df['PRE30'] = np.where(cleaned_df['PRE30'] == 'T', '0', cleaned_df['PRE30'] )\n",
    "cleaned_df['PRE30'] = np.where(cleaned_df['PRE30'] == 'F', '1', cleaned_df['PRE30'] )\n",
    "cleaned_df['PRE32'] = np.where(cleaned_df['PRE32'] == 'T', '0', cleaned_df['PRE32'] )\n",
    "cleaned_df['PRE32'] = np.where(cleaned_df['PRE32'] == 'F', '1', cleaned_df['PRE32'] )\n",
    "cleaned_df['Risk1Yr'] = np.where(cleaned_df['Risk1Yr'] == 'T', '0', cleaned_df['Risk1Yr'] )\n",
    "cleaned_df['Risk1Yr'] = np.where(cleaned_df['Risk1Yr'] == 'F', '1', cleaned_df['Risk1Yr'] )\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['DGN'] = cleaned_df['DGN'].astype(int)\n",
    "cleaned_df['PRE6'] = cleaned_df['PRE6'].astype(int)\n",
    "cleaned_df['PRE7'] = cleaned_df['PRE7'].astype(int)\n",
    "cleaned_df['PRE8'] = cleaned_df['PRE8'].astype(int)\n",
    "cleaned_df['PRE9'] = cleaned_df['PRE9'].astype(int)\n",
    "cleaned_df['PRE10'] = cleaned_df['PRE10'].astype(int)\n",
    "cleaned_df['PRE11'] = cleaned_df['PRE11'].astype(int)\n",
    "cleaned_df['PRE14'] = cleaned_df['PRE14'].astype(int)\n",
    "cleaned_df['PRE17'] = cleaned_df['PRE17'].astype(int)\n",
    "cleaned_df['PRE19'] = cleaned_df['PRE19'].astype(int)\n",
    "cleaned_df['PRE25'] = cleaned_df['PRE25'].astype(int)\n",
    "cleaned_df['PRE30'] = cleaned_df['PRE30'].astype(int)\n",
    "cleaned_df['PRE32'] = cleaned_df['PRE32'].astype(int)\n",
    "cleaned_df['Risk1Yr'] = cleaned_df['Risk1Yr'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling on Risk1Yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop('Risk1Yr', axis=1)\n",
    "y = cleaned_df['Risk1Yr']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=16))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV(estimator=SVC(kernel='linear'),\n",
    "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
    "             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test_scaled)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "metrics.f1_score(y_test, predictions, average='weighted', labels=np.unique(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"T\", \"F\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pete Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pete_df = df.drop(columns = [\"DGN\", \"PRE6\", \"PRE7\", 'PRE8', 'PRE9', 'PRE10', 'PRE11', 'PRE17', 'PRE19',\n",
    "             'PRE25', 'PRE30', 'PRE32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['PRE14'] = np.where(cleaned_df['PRE14'] == 'OC11', '11', cleaned_df['PRE14'] )\n",
    "cleaned_df['PRE14'] = np.where(cleaned_df['PRE14'] == 'OC12', '12', cleaned_df['PRE14'] )\n",
    "cleaned_df['PRE14'] = np.where(cleaned_df['PRE14'] == 'OC13', '13', cleaned_df['PRE14'] )\n",
    "cleaned_df['PRE14'] = np.where(cleaned_df['PRE14'] == 'OC14', '14', cleaned_df['PRE14'] )\n",
    "cleaned_df['Risk1Yr'] = np.where(cleaned_df['Risk1Yr'] == 'T', '0', cleaned_df['Risk1Yr'] )\n",
    "cleaned_df['Risk1Yr'] = np.where(cleaned_df['Risk1Yr'] == 'F', '1', cleaned_df['Risk1Yr'] )\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['PRE14'] = cleaned_df['PRE14'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_df = cleaned_df[cleaned_df[\"Risk1Yr\"] == '1']\n",
    "survived_df.rename(columns={\"PRE4\": \"FVC\", \"PRE5\": \"FEV\",\n",
    "                  \"PRE14\": \"TumorSize\", \"AGE\": \"Age\"}, inplace=True)\n",
    "survived_df = survived_df.drop(\"Risk1Yr\", axis=1)\n",
    "survived_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_df.describe(include='all').loc[['mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notSurvived_df = cleaned_df[cleaned_df[\"Risk1Yr\"] == '0']\n",
    "notSurvived_df.rename(columns={\"PRE4\": \"FVC\", \"PRE5\": \"FEV\",\n",
    "                  \"PRE14\": \"TumorSize\", \"AGE\": \"Age\"}, inplace=True)\n",
    "notSurvived_df = notSurvived_df.drop(\"Risk1Yr\", axis=1)\n",
    "notSurvived_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notSurvived_df.describe(include='all').loc[['mean']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
